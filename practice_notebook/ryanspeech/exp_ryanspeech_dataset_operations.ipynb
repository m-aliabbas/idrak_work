{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db9d0c8-bbbf-4b7d-a630-c48e4cacb189",
   "metadata": {},
   "source": [
    "Installing Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8016846f-c4d5-41ef-8e95-32cc048ff3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.9.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/dist-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.23.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.45.1->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.45.1->librosa) (63.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601b774-4d1f-4542-8a73-200ec5a818fc",
   "metadata": {},
   "source": [
    "Importing Required Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cac479d-34d2-4a74-9aad-9eddcccaebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset,Audio #for Huggingface Dataset Works\n",
    "import librosa\n",
    "import pandas as pd \n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038554a6-d168-48f4-94e6-160aa97a65c4",
   "metadata": {},
   "source": [
    "Path of Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1f6534-47c1-409c-b216-458ebe98fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_repo='Roh/ryanspeech'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e451d57-8ea3-4561-83cd-2516ef658492",
   "metadata": {},
   "source": [
    "Getting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88577682-5d5b-4ee1-8b23-b00aeee27d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: ryanspeech/male\n",
      "Reusing dataset ryanspeech (/root/.cache/huggingface/datasets/Roh___ryanspeech/male/1.0.0/6aa3c2ab705fac229e230a018a6e7a808e0b67053481894fbe2f8265f2b1acb7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ebc3641dc740d8ac9395bc6f6a16b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ryanspeech=load_dataset(dataset_repo,ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5285f84-c499-466f-bc43-4ea56b41e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_to_audiodataset(dataset):\n",
    "    '''\n",
    "    ##### IDRAK AI Experiments #####\n",
    "    this function get a dataset object of hugging face and return us audio_paths, and texts\n",
    "    \n",
    "    arguments: \n",
    "        dataset: hugging face dataset dictionary\n",
    "        \n",
    "    returns:\n",
    "        audio_paths(list): paths to audio \n",
    "        texts(list) : list of transcripts\n",
    "    '''\n",
    "    audio_paths=[]\n",
    "    texts=[]\n",
    "    for i in range(len(dataset)):\n",
    "        audio_path=dataset[i]['audio']['path']\n",
    "        text=dataset[i]['text']\n",
    "        print('Working on',text,audio_path,end=\"\\r\")\n",
    "        audio_paths.append(audio_path)\n",
    "        texts.append(text)\n",
    "    return audio_paths,texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbaef2f-dca2-4e5a-9f5d-b650f37f33d7",
   "metadata": {},
   "source": [
    "getting only training text and audio_file names; we are will split it later on to train and text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "914c62d2-a2f3-4a3b-a3e6-37e6f47b50d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on \"I've been thinking of the same things,\" Montgomery answered. \"There's my room with the outer door-\" /root/.cache/huggingface/datasets/downloads/extracted/f5a37597fcdec7b0d827b74fc85a0dac2ba997dfe66c63577d073091587b34a1/train/wavs/RY0001-1631.wav-1126.wavavs/RY0002-0305.wav409.wav-2110.wavs/RY0002-0230.wav.wavvavwav053.wav55.wav\r"
     ]
    }
   ],
   "source": [
    "train_audio_paths,train_texts=huggingface_to_audiodataset(ryanspeech['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e0a27b1-dc8c-4615-add2-4de556699088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['transcription']=train_texts\n",
    "df['audio']=train_audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cfce125-8485-465e-8567-6e3f89e8aa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The first PC computers appeared around 1975,</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sometimes it seems like the world is a cold, u...</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know it took all the courage I had to utter it.</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes! he might do that; so when he had got to t...</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They went together a long, long way, till they...</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>Okay, so check in Feb 25th and check out Feb 2...</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>The language we are now speaking is English.</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>I can certainly try to tell you about it.</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>That sounds great. Thank you very much for you...</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>\"I've been thinking of the same things,\" Montg...</td>\n",
       "      <td>/root/.cache/huggingface/datasets/downloads/ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7895 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcription  \\\n",
       "0          The first PC computers appeared around 1975,   \n",
       "1     Sometimes it seems like the world is a cold, u...   \n",
       "2     I know it took all the courage I had to utter it.   \n",
       "3     Yes! he might do that; so when he had got to t...   \n",
       "4     They went together a long, long way, till they...   \n",
       "...                                                 ...   \n",
       "7890  Okay, so check in Feb 25th and check out Feb 2...   \n",
       "7891       The language we are now speaking is English.   \n",
       "7892          I can certainly try to tell you about it.   \n",
       "7893  That sounds great. Thank you very much for you...   \n",
       "7894  \"I've been thinking of the same things,\" Montg...   \n",
       "\n",
       "                                                  audio  \n",
       "0     /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "1     /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "2     /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "3     /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "4     /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "...                                                 ...  \n",
       "7890  /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "7891  /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "7892  /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "7893  /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "7894  /root/.cache/huggingface/datasets/downloads/ex...  \n",
       "\n",
       "[7895 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc54548b-a90f-4492-a140-f3b944688e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ryanspeech.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07051853-bf86-47bc-a9d5-7530c4e3869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2ac13-776c-4099-995f-cc1c7d47e201",
   "metadata": {},
   "source": [
    "Getting Sample Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d04625e-15b0-4d67-b7f1-3ab821aaedac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioMetaData(sample_rate=22050, num_frames=37973, num_channels=1, bits_per_sample=16, encoding=PCM_S)\n"
     ]
    }
   ],
   "source": [
    "meta=torchaudio.info(df.audio.iloc[1100])\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3cb95ee9-49af-4096-88b4-2b1390ae7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanify(text):\n",
    "    #function to clean text\n",
    "    '''\n",
    "    #### IDRAK AI Text Cleaner#####\n",
    "    # this function required re module so import it\n",
    "    #i.e >>>import re\n",
    "    \n",
    "    It will first remove the unwantted symbols from text\n",
    "    using regular expression. Then Keep the numbers, alphabets, and question mark \n",
    "    \n",
    "    arguments:\n",
    "        text(string): text to be cleaned\n",
    "        \n",
    "    return: \n",
    "        text(string): cleaned text\n",
    "    '''\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]') #compile regulare expression for removing symbols\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z ?]') #compile regulare expression to keep wanted data\n",
    "    text=str(text)\n",
    "    text = text.lower() #making text to lower case\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)  #applying 1 and 2nd mentioned re\n",
    "    text = BAD_SYMBOLS_RE.sub(' ', text)\n",
    "    text=text.strip() #remove leading and tailing spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "677b0b8a-97b3-46ff-9cc2-44c9bc3e1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcription']=df['transcription'].apply(cleanify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e67a8d7-63b6-4339-b7ae-3b6fec674811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a00b7fe3-ed24-4235-b537-57270027d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43f42549-4c5e-4cf8-8839-1355c701bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(df,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e362012-5f78-4a55-8cef-29ce65034865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(df1=None,file_path=''):\n",
    "    transcriptions=list(df1.transcription.values) #making list of transcriptions\n",
    "    file_names=list(df1.audio.values) #making list of file names\n",
    "    file_names=[file_name for file_name in file_names] #appending directory containing audiosdata with file name\n",
    "    data_dict={'audio':file_names , 'transcription':transcriptions} #Hugging face need a dictionary of list for creating the dataset. \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67d4a565-897b-4693-8f94-2d0d63b12235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packing to Hugginface Dataset Regime and Pushing to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88103eb4-4578-49c7-b972-c20dbc1b85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict=make_dictionary(df1=df_train,file_path='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95fdf1c4-8547-4f01-9502-3d42f4f07097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict=make_dictionary(df1=df_test,file_path='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7803c772-1c61-4b71-8f64-3b0f29178ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset = Dataset.from_dict(train_dict,split='train').cast_column(\"audio\", Audio(sampling_rate=16000)) #fetching the adio from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a47b720e-f37f-48fc-921a-c9176e17503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_repo='m-aliabbas/idrak_ryanspeech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bfcffcfb-21dc-4c5c-9f20-57fa1a0a33a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefc5c3e38544671859b076c54e85906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0f57c770a84494ad58f85ffbf22b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/huggingface_hub/hf_api.py:1948: FutureWarning: `identical_ok` has no effect and is deprecated. It will be removed in 0.11.0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6924d0dee19f47f9abf06b3ecd00559f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_dataset.push_to_hub(dataset_repo) #commiting / pusshing dataset to Hugging face repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab41f58b-4413-417c-b342-fc1e56e26f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Training and Testing Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a900d9a-7bfd-480b-95d6-310f45207753",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset = Dataset.from_dict(test_dict,split='test').cast_column(\"audio\", Audio(sampling_rate=16000)) #fetching the adio from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40cbbcaf-cf79-46ab-936a-c4a00eaacc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e5d81c12ed4e3c983f81e507136e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9b13353d02431a9edc299ec7a1a4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe615ad46e414d71a28e817f78760af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "audio_dataset.push_to_hub(dataset_repo) #commiting / pusshing dataset to Hugging face repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf461cd2-f321-4b04-801f-e9043bb11056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking The Dataset Repo and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3d59538-1142-4e79-a480-1a4d3dd79431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d3c208bb4f4401bc6aac29ab14bf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration m-aliabbas--idrak_ryanspeech-caee615dadca058c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None (download: 1.02 GiB, generated: 1.05 GiB, post-processed: Unknown size, total: 2.07 GiB) to /root/.cache/huggingface/datasets/m-aliabbas___parquet/m-aliabbas--idrak_ryanspeech-caee615dadca058c/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2e1647451e43cea4cd167fae447d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024b684b87d24b2ca44b2594b6901895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/218M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8552438c684dff86efadd887ad608c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f718066223415a9ed4183bf5f32b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/437M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18df9ad65e674f19a7689790440d8c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/m-aliabbas___parquet/m-aliabbas--idrak_ryanspeech-caee615dadca058c/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34afb4a79dcd4f6880d4d02f8e9cb5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idrak_voice=load_dataset(dataset_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e7fd731-fa87-4510-ac97-9260d54b855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': None,\n",
       " 'array': array([ 3.96761867e-05, -8.31791544e-05,  4.91017366e-05, ...,\n",
       "        -3.79574425e-05,  1.59031853e-05,  0.00000000e+00]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idrak_voice['train'][4]['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fa45886f-c83a-40bb-98d7-5f963bc8d43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m-aliabbas/idrak_ryanspeech'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d253e9-a191-4405-88af-795ceac353d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
